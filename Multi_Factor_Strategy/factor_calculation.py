# -*- coding: utf-8 -*-
"""
ä¸­è¯1000å¤šå› å­ç­–ç•¥ - å› å­è®¡ç®—æ¨¡å—
å®ç°20ä¸ªå› å­çš„è®¡ç®—å‡½æ•°
"""

import numpy as np
import pandas as pd
from scipy import stats
from scipy.stats import skew, kurtosis
import warnings
import os
from pathlib import Path
from functools import partial
import time
warnings.filterwarnings('ignore')

# å°è¯•å¯¼å…¥å¹¶è¡Œè®¡ç®—å’ŒnumbaåŠ é€Ÿåº“
try:
    from numba import jit, prange, float64
    NUMBA_AVAILABLE = True
except ImportError:
    NUMBA_AVAILABLE = False
    # å®šä¹‰å ä½å‡½æ•°
    def jit(*args, **kwargs):
        def decorator(func):
            return func
        return decorator
    prange = range

try:
    from joblib import Parallel, delayed
    JOBLIB_AVAILABLE = True
except ImportError:
    JOBLIB_AVAILABLE = False

class FactorCalculator:
    """å› å­è®¡ç®—å™¨ç±»"""
    
    def __init__(self, price_data, mv_data=None, turnover_data=None, market_data=None, constituent_manager=None):
        """
        åˆå§‹åŒ–å› å­è®¡ç®—å™¨
        
        Parameters:
        -----------
        price_data : pd.DataFrame, ä»·æ ¼æ•°æ®ï¼Œå¿…é¡»åŒ…å«åˆ—ï¼šS_INFO_WINDCODE, TRADE_DT, CLOSE_PRICE, OPEN_PRICE, HIGH_PRICE, LOW_PRICE, CLOSE_ADJ, VOLUME, AMOUNT
        mv_data : pd.DataFrame, å¸‚å€¼æ•°æ®
        turnover_data : pd.DataFrame, æ¢æ‰‹ç‡æ•°æ®
        market_data : pd.DataFrame, å¸‚åœºæŒ‡æ•°æ•°æ®
        constituent_manager : ConstituentManager, æˆåˆ†è‚¡ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºåœ¨è®¡ç®—å› å­æ—¶è¿‡æ»¤æˆåˆ†è‚¡
        """
        self.price_data = price_data.copy()
        self.mv_data = mv_data
        self.turnover_data = turnover_data
        self.market_data = market_data
        self.constituent_manager = constituent_manager
        
        # æ•°æ®é¢„å¤„ç†
        self._preprocess_data()
        
    def _preprocess_data(self):
        """æ•°æ®é¢„å¤„ç†ï¼šè®¡ç®—æ”¶ç›Šç‡ç­‰åŸºç¡€æŒ‡æ ‡"""
        # æŒ‰è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸæ’åº
        self.price_data = self.price_data.sort_values(['S_INFO_WINDCODE', 'TRADE_DT'])
        
        # ç¡®ä¿CLOSE_ADJå­˜åœ¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼Œä½¿ç”¨CLOSE_PRICEï¼‰
        if 'CLOSE_ADJ' not in self.price_data.columns:
            if 'CLOSE_PRICE' in self.price_data.columns:
                self.price_data['CLOSE_ADJ'] = self.price_data['CLOSE_PRICE']
                print("âš ï¸  CLOSE_ADJå­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨CLOSE_PRICEä»£æ›¿ï¼ˆæœªå¤æƒï¼‰")
            else:
                raise ValueError("ä»·æ ¼æ•°æ®ä¸­ç¼ºå°‘CLOSE_PRICEæˆ–CLOSE_ADJå­—æ®µ")
        
        # è®¡ç®—æ”¶ç›Šç‡ï¼ˆä½¿ç”¨å¤æƒæ”¶ç›˜ä»·ï¼‰
        self.price_data['RETURN'] = self.price_data.groupby('S_INFO_WINDCODE')['CLOSE_ADJ'].pct_change()
        
        # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡ï¼ˆæŸäº›å› å­éœ€è¦ï¼‰
        self.price_data['LOG_RETURN'] = np.log(self.price_data['CLOSE_ADJ'] / self.price_data.groupby('S_INFO_WINDCODE')['CLOSE_ADJ'].shift(1))
        
        # ä½¿ç”¨VWAPå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™ç”¨æˆäº¤é‡‘é¢/æˆäº¤é‡è®¡ç®—ï¼Œå†å¦åˆ™ç”¨æ”¶ç›˜ä»·
        if 'VWAP' not in self.price_data.columns or self.price_data['VWAP'].isna().all():
            if 'AMOUNT' in self.price_data.columns and 'VOLUME' in self.price_data.columns:
                self.price_data['VWAP'] = self.price_data['AMOUNT'] / (self.price_data['VOLUME'] + 1e-10)
                print("âš ï¸  VWAPå­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨æˆäº¤é‡‘é¢/æˆäº¤é‡è®¡ç®—")
            else:
                self.price_data['VWAP'] = self.price_data['CLOSE_PRICE']
                print("âš ï¸  VWAPå­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨æ”¶ç›˜ä»·ä»£æ›¿")
        else:
            # å¦‚æœVWAPå­—æ®µå­˜åœ¨ä½†æœ‰ç¼ºå¤±å€¼ï¼Œç”¨æˆäº¤é‡‘é¢/æˆäº¤é‡å¡«å……
            if self.price_data['VWAP'].isna().any():
                mask = self.price_data['VWAP'].isna()
                if 'AMOUNT' in self.price_data.columns and 'VOLUME' in self.price_data.columns:
                    self.price_data.loc[mask, 'VWAP'] = (
                        self.price_data.loc[mask, 'AMOUNT'] / 
                        (self.price_data.loc[mask, 'VOLUME'] + 1e-10)
                    )
                else:
                    self.price_data.loc[mask, 'VWAP'] = self.price_data.loc[mask, 'CLOSE_PRICE']
        
        # å¦‚æœå¸‚åœºæ•°æ®å­˜åœ¨ï¼Œåˆå¹¶
        if self.market_data is not None:
            self.price_data = self.price_data.merge(
                self.market_data[['TRADE_DT', 'MARKET_RETURN']], 
                on='TRADE_DT', 
                how='left'
            )
        
        # åˆå¹¶å¸‚å€¼æ•°æ®
        if self.mv_data is not None:
            self.price_data = self.price_data.merge(
                self.mv_data[['S_INFO_WINDCODE', 'TRADE_DT', 'TOTAL_MV']],
                on=['S_INFO_WINDCODE', 'TRADE_DT'],
                how='left'
            )
        
        # åˆå¹¶æ¢æ‰‹ç‡æ•°æ®
        if self.turnover_data is not None:
            # æ£€æŸ¥æ¢æ‰‹ç‡æ•°æ®ä¸­æ˜¯å¦æœ‰TURNOVER_RATEå­—æ®µ
            if 'TURNOVER_RATE' in self.turnover_data.columns:
                self.price_data = self.price_data.merge(
                    self.turnover_data[['S_INFO_WINDCODE', 'TRADE_DT', 'TURNOVER_RATE']],
                    on=['S_INFO_WINDCODE', 'TRADE_DT'],
                    how='left'
                )
            elif 'AMOUNT' in self.turnover_data.columns:
                # å¦‚æœæ²¡æœ‰TURNOVER_RATEï¼Œåˆå¹¶æˆäº¤é‡‘é¢ï¼Œåç»­å¯ä»¥ç»“åˆå¸‚å€¼è®¡ç®—æ¢æ‰‹ç‡
                self.price_data = self.price_data.merge(
                    self.turnover_data[['S_INFO_WINDCODE', 'TRADE_DT', 'AMOUNT']],
                    on=['S_INFO_WINDCODE', 'TRADE_DT'],
                    how='left',
                    suffixes=('', '_turnover')
                )
        
        # å¦‚æœæ¢æ‰‹ç‡ä¸å­˜åœ¨ï¼Œå°è¯•ä»æˆäº¤é‡‘é¢å’Œå¸‚å€¼è®¡ç®—
        if 'TURNOVER_RATE' not in self.price_data.columns or self.price_data['TURNOVER_RATE'].isna().all():
            if 'AMOUNT' in self.price_data.columns and 'TOTAL_MV' in self.price_data.columns:
                self.price_data['TURNOVER_RATE'] = self.price_data['AMOUNT'] / (self.price_data['TOTAL_MV'] + 1e8)
                print("âš ï¸  æ¢æ‰‹ç‡å­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨æˆäº¤é‡‘é¢/å¸‚å€¼è®¡ç®—")
            elif 'AMOUNT' in self.price_data.columns:
                # å¦‚æœæ²¡æœ‰å¸‚å€¼æ•°æ®ï¼Œæš‚æ—¶ç”¨0å¡«å……ï¼Œåç»­éœ€è¦å¸‚å€¼æ•°æ®
                self.price_data['TURNOVER_RATE'] = 0.0
                print("âš ï¸  æ¢æ‰‹ç‡å­—æ®µä¸å­˜åœ¨ä¸”ç¼ºå°‘å¸‚å€¼æ•°æ®ï¼Œæš‚æ—¶è®¾ä¸º0")
            else:
                self.price_data['TURNOVER_RATE'] = 0.05  # é»˜è®¤å€¼
                print("âš ï¸  æ¢æ‰‹ç‡å­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼0.05")
    
    def pivot_to_wide_format(self, df, value_col, date_col='TRADE_DT', stock_col='S_INFO_WINDCODE'):
        """
        å°†é•¿æ ¼å¼æ•°æ®è½¬æ¢ä¸ºå®½æ ¼å¼ï¼ˆè‚¡ç¥¨ä¸ºè¡Œï¼Œæ—¥æœŸä¸ºåˆ—ï¼‰
        
        Parameters:
        -----------
        df : pd.DataFrame
        value_col : str, å€¼åˆ—å
        date_col : str, æ—¥æœŸåˆ—å
        stock_col : str, è‚¡ç¥¨ä»£ç åˆ—å
        
        Returns:
        --------
        pd.DataFrame : å®½æ ¼å¼æ•°æ®ï¼Œindexä¸ºè‚¡ç¥¨ä»£ç ï¼Œcolumnsä¸ºæ—¥æœŸ
        """
        # ä½¿ç”¨pivotè€Œä¸æ˜¯pivot_tableï¼Œé¿å…èšåˆ
        df_wide = df.pivot(
            index=stock_col,
            columns=date_col,
            values=value_col
        )
        return df_wide
    
    # ==================== Factor 1: SCC ====================
    def calculate_SCC(self, window=252):
        """
        Factor 1: Spatial Centrality Centrality (SCC)
        åŸºäºè‚¡ç¥¨é—´ç›¸å…³ç³»æ•°çš„ç©ºé—´ä¸­å¿ƒæ€§
        ä½¿ç”¨numbaåŠ é€Ÿä¼˜åŒ–
        """
        print("è®¡ç®—å› å­1: SCC...")
        returns_wide = self.pivot_to_wide_format(
            self.price_data[['S_INFO_WINDCODE', 'TRADE_DT', 'RETURN']].dropna(),
            'RETURN'
        )
        
        scc_factors = []
        dates = returns_wide.columns
        returns_matrix = returns_wide.values  # è½¬æ¢ä¸ºnumpyæ•°ç»„
        
        for i, date in enumerate(dates):
            if i < window:
                continue
            
            # è·å–è¿‡å»windowå¤©çš„æ”¶ç›Šç‡æ•°æ®
            start_idx = max(0, i - window + 1)
            returns_window = returns_matrix[:, start_idx:i+1]
            
            # ä½¿ç”¨ä¼˜åŒ–çš„ç›¸å…³ç³»æ•°è®¡ç®—
            if NUMBA_AVAILABLE and returns_window.shape[1] >= window // 2:
                # ä½¿ç”¨numbaåŠ é€Ÿç‰ˆæœ¬
                try:
                    avg_corr_array = _calculate_scc_optimized(returns_window)
                    avg_corr = pd.Series(avg_corr_array, index=returns_wide.index)
                except Exception as e:
                    # å›é€€åˆ°pandasç‰ˆæœ¬
                    returns_window_df = pd.DataFrame(
                        returns_window, 
                        index=returns_wide.index,
                        columns=dates[start_idx:i+1]
                    )
                    correlations = returns_window_df.T.corr()
                    avg_corr = correlations.mean(axis=1) - 1 / len(correlations)
                    avg_corr = avg_corr * len(correlations) / (len(correlations) - 1)
            else:
                # ä½¿ç”¨pandasç‰ˆæœ¬
                returns_window_df = pd.DataFrame(
                    returns_window, 
                    index=returns_wide.index,
                    columns=dates[start_idx:i+1]
                )
                correlations = returns_window_df.T.corr()
                avg_corr = correlations.mean(axis=1) - 1 / len(correlations)
                avg_corr = avg_corr * len(correlations) / (len(correlations) - 1)
            
            scc_series = pd.Series(avg_corr.values, index=returns_wide.index, name=date)
            scc_factors.append(scc_series)
        
        scc_df = pd.DataFrame(scc_factors).T
        print(f"âœ… SCCå› å­è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {scc_df.shape}")
        return scc_df
    
    # ==================== Factor 2: TCC ====================
    def calculate_TCC(self, window=252):
        """
        Factor 2: Temporal Centrality Centrality (TCC)
        æ—¶é—´ç»´åº¦ä¸Šçš„ä¸­å¿ƒæ€§ï¼Œè¡¡é‡è‚¡ç¥¨æ”¶ç›Šç‡ç›¸å¯¹å¸‚åœºå¹³å‡çš„ç¨³å®šæ€§
        """
        print("è®¡ç®—å› å­2: TCC...")
        
        if 'MARKET_RETURN' not in self.price_data.columns:
            print("âš ï¸  ç¼ºå°‘å¸‚åœºæ”¶ç›Šç‡æ•°æ®ï¼Œä½¿ç”¨æˆªé¢å‡å€¼ä»£æ›¿")
            self.price_data['MARKET_RETURN'] = self.price_data.groupby('TRADE_DT')['RETURN'].transform('mean')
        
        # è®¡ç®—æ ‡å‡†åŒ–åå·®
        self.price_data['Z_SCORE'] = self.price_data.groupby('TRADE_DT').apply(
            lambda x: (x['RETURN'] - x['RETURN'].mean()) / (x['RETURN'].std() + 1e-8)
        ).reset_index(level=0, drop=True)
        
        self.price_data['Z_SQUARED'] = self.price_data['Z_SCORE'] ** 2
        
        # æ»šåŠ¨çª—å£è®¡ç®—E[zÂ²]çš„å€’æ•°
        tcc_list = []
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT')
            stock_data['TCC'] = 1 / (stock_data['Z_SQUARED'].rolling(window=window, min_periods=60).mean() + 1e-8)
            tcc_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'TCC']])
        
        tcc_df = pd.concat(tcc_list, ignore_index=True)
        tcc_wide = self.pivot_to_wide_format(tcc_df, 'TCC')
        
        print(f"âœ… TCCå› å­è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {tcc_wide.shape}")
        return tcc_wide
    
    # ==================== Factor 3: APB ====================
    def calculate_APB(self, window=20):
        """
        Factor 3: Average Price Bias (APB)
        å¹³å‡ä»·æ ¼åå·®ï¼Œè¡¡é‡ä¹°å–å‹åŠ›
        """
        print("è®¡ç®—å› å­3: APB...")
        
        apb_list = []
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
            
            # è®¡ç®—ç­‰æƒé‡å¹³å‡ä»·æ ¼
            stock_data['EW_PRICE'] = stock_data['CLOSE_PRICE'].rolling(window=window).mean()
            
            # è®¡ç®—æˆäº¤é‡åŠ æƒå¹³å‡ä»·æ ¼ï¼ˆVWAPï¼‰
            stock_data['VWAP_WINDOW'] = (
                (stock_data['CLOSE_PRICE'] * stock_data['VOLUME']).rolling(window=window).sum() /
                stock_data['VOLUME'].rolling(window=window).sum()
            )
            
            # APB = log(ç­‰æƒé‡å¹³å‡ä»·æ ¼ / VWAP)
            stock_data['APB'] = np.log(stock_data['EW_PRICE'] / (stock_data['VWAP_WINDOW'] + 1e-8))
            
            apb_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'APB']])
        
        apb_df = pd.concat(apb_list, ignore_index=True)
        apb_wide = self.pivot_to_wide_format(apb_df, 'APB')
        
        print(f"âœ… APBå› å­è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {apb_wide.shape}")
        return apb_wide
    
    # ==================== Factor 4-7: ARC/VRC/SRC/KRC ====================
    def calculate_relative_cost_moments(self, max_lookback=252):
        """
        Factor 4-7: ARC/VRC/SRC/KRC (Average/Variance/Skewness/Kurtosis of Relative Cost)
        ç›¸å¯¹æˆæœ¬çš„å„é˜¶çŸ©
        ä½¿ç”¨numbaåŠ é€Ÿä¼˜åŒ–
        """
        print("è®¡ç®—å› å­4-7: ARC/VRC/SRC/KRC...")
        
        if 'TURNOVER_RATE' not in self.price_data.columns:
            print("âš ï¸  ç¼ºå°‘æ¢æ‰‹ç‡æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            self.price_data['TURNOVER_RATE'] = 0.05
        
        # ä½¿ç”¨å¹¶è¡Œè®¡ç®—å¤„ç†å¤šåªè‚¡ç¥¨
        if JOBLIB_AVAILABLE:
            import multiprocessing
            n_jobs = min(multiprocessing.cpu_count(), 4)  # é™åˆ¶æœ€å¤§å¹¶è¡Œæ•°ï¼Œé¿å…å†…å­˜é—®é¢˜
            print(f"   ä½¿ç”¨å¹¶è¡Œè®¡ç®—ï¼ˆ{n_jobs}ä¸ªæ ¸å¿ƒï¼‰...")
            
            stocks = self.price_data['S_INFO_WINDCODE'].unique().tolist()
            results_list = Parallel(n_jobs=n_jobs, backend='threading', verbose=0)(
                delayed(self._calculate_relative_cost_single_stock)(stock, max_lookback)
                for stock in stocks
            )
            
            # åˆå¹¶ç»“æœ
            results = {'ARC': [], 'VRC': [], 'SRC': [], 'KRC': []}
            for stock_results in results_list:
                for col in ['ARC', 'VRC', 'SRC', 'KRC']:
                    if stock_results[col] is not None:
                        results[col].append(stock_results[col])
        else:
            # ä¸²è¡Œè®¡ç®—
            results = {}
            stocks = self.price_data['S_INFO_WINDCODE'].unique()
            for idx, stock in enumerate(stocks):
                if (idx + 1) % 100 == 0:
                    print(f"   å¤„ç†è¿›åº¦: {idx + 1}/{len(stocks)}")
                stock_result = self._calculate_relative_cost_single_stock(stock, max_lookback)
                for col in ['ARC', 'VRC', 'SRC', 'KRC']:
                    if col not in results:
                        results[col] = []
                    if stock_result[col] is not None:
                        results[col].append(stock_result[col])
        
        factor_dfs = {}
        for factor_name, factor_list in results.items():
            if len(factor_list) > 0:
                factor_df = pd.concat(factor_list, ignore_index=True)
                factor_wide = self.pivot_to_wide_format(factor_df, factor_name)
                factor_dfs[factor_name] = factor_wide
        
        print(f"âœ… ARC/VRC/SRC/KRCå› å­è®¡ç®—å®Œæˆ")
        return factor_dfs
    
    def _calculate_relative_cost_single_stock(self, stock, max_lookback):
        """è®¡ç®—å•åªè‚¡ç¥¨çš„ç›¸å¯¹æˆæœ¬çŸ©ï¼ˆç”¨äºå¹¶è¡Œè®¡ç®—ï¼‰"""
        stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
        
        if len(stock_data) <= max_lookback:
            return {'ARC': None, 'VRC': None, 'SRC': None, 'KRC': None}
        
        arc_list, vrc_list, src_list, krc_list = [], [], [], []
        prices = stock_data['CLOSE_ADJ'].values
        turnovers = stock_data['TURNOVER_RATE'].fillna(0.05).values
        
        for i in range(len(stock_data)):
            if i < max_lookback:
                arc_list.append(np.nan)
                vrc_list.append(np.nan)
                src_list.append(np.nan)
                krc_list.append(np.nan)
                continue
            
            # è·å–å†å²æ•°æ®çª—å£
            start_idx = max(0, i - max_lookback + 1)
            hist_prices = prices[start_idx:i+1]
            hist_turnovers = turnovers[start_idx:i+1]
            current_price = prices[i]
            
            # è®¡ç®—ç›¸å¯¹æ”¶ç›Šç‡
            relative_returns = np.full(len(hist_prices), np.nan)
            for j in range(1, len(hist_prices)):
                if hist_prices[j-1] > 0:
                    relative_returns[j] = (current_price / hist_prices[j-1] - 1)
            relative_returns[0] = 0.0
            
            # è®¡ç®—æ¢æ‰‹ç‡æƒé‡
            turnover_weights = np.zeros(len(hist_prices))
            for j in range(len(hist_prices)):
                days_ago = len(hist_prices) - 1 - j
                turnover = hist_turnovers[j] if not np.isnan(hist_turnovers[j]) else 0.05
                
                # è®¡ç®—ç”Ÿå­˜æ¦‚ç‡
                if days_ago == 0:
                    survival_prob = 1.0
                else:
                    avg_turnover = np.nanmean(hist_turnovers[:j+1])
                    if np.isnan(avg_turnover):
                        avg_turnover = 0.05
                    survival_prob = (1 - avg_turnover) ** days_ago
                
                turnover_weights[j] = turnover * survival_prob
            
            # å½’ä¸€åŒ–æƒé‡
            weight_sum = np.nansum(turnover_weights)
            if weight_sum > 1e-10:
                turnover_weights = turnover_weights / weight_sum
            else:
                turnover_weights = np.ones(len(hist_prices)) / len(hist_prices)
            
            # ä½¿ç”¨numbaåŠ é€Ÿçš„åŠ æƒçŸ©è®¡ç®—
            valid_mask = ~np.isnan(relative_returns)
            if valid_mask.sum() < 10:  # è‡³å°‘éœ€è¦10ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹
                arc_list.append(np.nan)
                vrc_list.append(np.nan)
                src_list.append(np.nan)
                krc_list.append(np.nan)
                continue
            
            valid_returns = relative_returns[valid_mask]
            valid_weights = turnover_weights[valid_mask]
            valid_weights = valid_weights / np.sum(valid_weights)  # é‡æ–°å½’ä¸€åŒ–
            
            # è®¡ç®—åŠ æƒçŸ©
            arc, vrc, src, krc = _calculate_weighted_moments_numba(valid_returns, valid_weights)
            
            arc_list.append(arc if not np.isnan(arc) else 0.0)
            vrc_list.append(vrc if not np.isnan(vrc) else 0.0)
            src_list.append(src if not np.isnan(src) else 0.0)
            krc_list.append(krc if not np.isnan(krc) else 0.0)
        
        stock_data['ARC'] = arc_list
        stock_data['VRC'] = vrc_list
        stock_data['SRC'] = src_list
        stock_data['KRC'] = krc_list
        
        return {
            'ARC': stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'ARC']],
            'VRC': stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'VRC']],
            'SRC': stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'SRC']],
            'KRC': stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'KRC']]
        }
    
    # ==================== Factor 8: 20-day Price Bias ====================
    def calculate_BIAS(self, window=20):
        """
        Factor 8: 20-day Price Bias (BIAS)
        ä»·æ ¼åç¦»20æ—¥å‡çº¿çš„ç¨‹åº¦
        """
        print("è®¡ç®—å› å­8: BIAS...")
        
        bias_list = []
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
            
            # è®¡ç®—20æ—¥ç§»åŠ¨å¹³å‡
            stock_data['MA20'] = stock_data['CLOSE_PRICE'].rolling(window=window).mean()
            
            # BIAS = (å½“å‰ä»·æ ¼ - MA20) / MA20
            stock_data['BIAS'] = (stock_data['CLOSE_PRICE'] - stock_data['MA20']) / (stock_data['MA20'] + 1e-8)
            
            bias_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'BIAS']])
        
        bias_df = pd.concat(bias_list, ignore_index=True)
        bias_wide = self.pivot_to_wide_format(bias_df, 'BIAS')
        
        print(f"âœ… BIASå› å­è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {bias_wide.shape}")
        return bias_wide
    
    # ==================== Factor 9: 20-day Turnover Bias ====================
    def calculate_TurnoverBias(self, window=20):
        """
        Factor 9: 20-day Turnover Bias
        æ¢æ‰‹ç‡åç¦»20æ—¥å‡å€¼çš„ç¨‹åº¦
        """
        print("è®¡ç®—å› å­9: TurnoverBias...")
        
        if 'TURNOVER_RATE' not in self.price_data.columns:
            print("âš ï¸  ç¼ºå°‘æ¢æ‰‹ç‡æ•°æ®ï¼Œä½¿ç”¨æˆäº¤é‡/å¸‚å€¼è¿‘ä¼¼")
            self.price_data['TURNOVER_RATE'] = self.price_data['AMOUNT'] / (self.price_data['TOTAL_MV'] + 1e8)
        
        turnover_bias_list = []
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
            
            # è®¡ç®—20æ—¥æ¢æ‰‹ç‡å‡å€¼
            stock_data['TURNOVER_MA20'] = stock_data['TURNOVER_RATE'].rolling(window=window).mean()
            
            # Turnover Bias = (å½“å‰æ¢æ‰‹ç‡ - MA20) / MA20
            stock_data['TURNOVER_BIAS'] = (stock_data['TURNOVER_RATE'] - stock_data['TURNOVER_MA20']) / (stock_data['TURNOVER_MA20'] + 1e-8)
            
            turnover_bias_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'TURNOVER_BIAS']])
        
        turnover_bias_df = pd.concat(turnover_bias_list, ignore_index=True)
        turnover_bias_wide = self.pivot_to_wide_format(turnover_bias_df, 'TURNOVER_BIAS')
        
        print(f"âœ… TurnoverBiaså› å­è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {turnover_bias_wide.shape}")
        return turnover_bias_wide
    
    # ==================== Factor 10: Ratio of New High Days ====================
    def calculate_NewHighRatio(self, window=20, lookback=20):
        """
        Factor 10: Ratio of New High Days (20-day)
        è¿‡å»20å¤©å†…åˆ›æ–°é«˜çš„å¤©æ•°æ¯”ä¾‹
        """
        print("è®¡ç®—å› å­10: NewHighRatio...")
        
        newhigh_list = []
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
            
            # è®¡ç®—æ»šåŠ¨20æ—¥æœ€é«˜ä»·
            stock_data['ROLLING_HIGH'] = stock_data['HIGH_PRICE'].rolling(window=window).max()
            
            # åˆ¤æ–­æ¯æ—¥æ˜¯å¦åˆ›æ–°é«˜
            stock_data['IS_NEW_HIGH'] = (stock_data['HIGH_PRICE'] >= stock_data['ROLLING_HIGH']).astype(int)
            
            # è®¡ç®—è¿‡å»lookbackå¤©å†…åˆ›æ–°é«˜çš„å¤©æ•°æ¯”ä¾‹
            stock_data['NEW_HIGH_RATIO'] = stock_data['IS_NEW_HIGH'].rolling(window=lookback).sum() / lookback
            
            newhigh_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'NEW_HIGH_RATIO']])
        
        newhigh_df = pd.concat(newhigh_list, ignore_index=True)
        newhigh_wide = self.pivot_to_wide_format(newhigh_df, 'NEW_HIGH_RATIO')
        
        print(f"âœ… NewHighRatioå› å­è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {newhigh_wide.shape}")
        return newhigh_wide
    
    # ==================== Factor 11: Volatility Factor ====================
    def calculate_VolatilityFactor(self, window=20):
        """
        Factor 11: Volatility Factor (ID_Vol, ID_Vol_deCorr)
        ç‰¹è´¨æ³¢åŠ¨ç‡å› å­ï¼Œä½¿ç”¨Fama-Frenchä¸‰å› å­æ¨¡å‹æ®‹å·®
        """
        print("è®¡ç®—å› å­11: VolatilityFactor...")
        
        # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ä½¿ç”¨æ”¶ç›Šç‡çš„æ ‡å‡†å·®ä½œä¸ºç‰¹è´¨æ³¢åŠ¨ç‡
        # å®Œæ•´ç‰ˆæœ¬éœ€è¦ä½¿ç”¨Fama-Frenchä¸‰å› å­æ¨¡å‹å›å½’
        
        vol_list = []
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
            
            # è®¡ç®—æ»šåŠ¨çª—å£çš„ç‰¹è´¨æ³¢åŠ¨ç‡ï¼ˆç®€åŒ–ï¼šä½¿ç”¨æ”¶ç›Šç‡æ ‡å‡†å·®ï¼‰
            stock_data['ID_VOL'] = stock_data['RETURN'].rolling(window=window).std() * np.sqrt(252)  # å¹´åŒ–
            
            vol_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'ID_VOL']])
        
        vol_df = pd.concat(vol_list, ignore_index=True)
        vol_wide = self.pivot_to_wide_format(vol_df, 'ID_VOL')
        
        # æœˆåº¦æˆªé¢å»ç›¸å…³ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        vol_decorr = vol_wide.copy()
        # è¿™é‡Œåº”è¯¥è¿›è¡Œæœˆåº¦æˆªé¢å›å½’ï¼Œç®€åŒ–å¤„ç†ç•¥è¿‡
        
        print(f"âœ… VolatilityFactorå› å­è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {vol_wide.shape}")
        return vol_wide, vol_decorr
    
    # ==================== Factor 12: Turnover Rate Factor ====================
    def calculate_TurnoverFactor(self, window=20):
        """
        Factor 12: Turnover Rate Factor (Turn20)
        è¿‡å»20å¤©çš„å¹³å‡æ¢æ‰‹ç‡ï¼Œå¸‚å€¼è°ƒæ•´
        """
        print("è®¡ç®—å› å­12: TurnoverFactor...")
        
        if 'TURNOVER_RATE' not in self.price_data.columns:
            print("âš ï¸  ç¼ºå°‘æ¢æ‰‹ç‡æ•°æ®ï¼Œä½¿ç”¨æˆäº¤é‡/å¸‚å€¼è¿‘ä¼¼")
            self.price_data['TURNOVER_RATE'] = self.price_data['AMOUNT'] / (self.price_data['TOTAL_MV'] + 1e8)
        
        turnover_list = []
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
            
            # è®¡ç®—è¿‡å»20å¤©å¹³å‡æ¢æ‰‹ç‡
            stock_data['TURN20'] = stock_data['TURNOVER_RATE'].rolling(window=window).mean()
            
            turnover_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'TURN20']])
        
        turnover_df = pd.concat(turnover_list, ignore_index=True)
        turnover_wide = self.pivot_to_wide_format(turnover_df, 'TURN20')
        
        # å¸‚å€¼è°ƒæ•´ï¼ˆåœ¨æˆªé¢æ ‡å‡†åŒ–ï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æŒ‰å¸‚å€¼åˆ†ç»„è°ƒæ•´
        
        print(f"âœ… TurnoverFactorå› å­è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {turnover_wide.shape}")
        return turnover_wide
    
    # ==================== Factor 13-14: CGO & RCGO ====================
    def calculate_CGO_RCGO(self, window=252):
        """
        Factor 13-14: Capital Gain Overhang (CGO) & Residual CGO (RCGO)
        èµ„æœ¬æ”¶ç›Šæ‚¬ç½®å› å­
        """
        print("è®¡ç®—å› å­13-14: CGO & RCGO...")
        
        if 'TURNOVER_RATE' not in self.price_data.columns:
            print("âš ï¸  ç¼ºå°‘æ¢æ‰‹ç‡æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            self.price_data['TURNOVER_RATE'] = 0.05
        
        cgo_list, rcgo_list = [], []
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
            
            cgo_values, rcgo_values = [], []
            
            for i in range(len(stock_data)):
                if i < window:
                    cgo_values.append(np.nan)
                    rcgo_values.append(np.nan)
                    continue
                
                hist_data = stock_data.iloc[max(0, i-window+1):i+1].copy()
                hist_data = hist_data.reset_index(drop=True)
                
                current_price = hist_data.iloc[-1]['CLOSE_ADJ']
                
                # è®¡ç®—å¹³å‡æˆæœ¬ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                # å®Œæ•´ç‰ˆæœ¬éœ€è¦æ ¹æ®æ¢æ‰‹ç‡å’Œä»·æ ¼å†å²è®¡ç®—
                avg_cost = hist_data['CLOSE_ADJ'].mean()
                
                # CGO = (å½“å‰ä»·æ ¼ - å¹³å‡æˆæœ¬) / å¹³å‡æˆæœ¬
                cgo = (current_price - avg_cost) / (avg_cost + 1e-8)
                cgo_values.append(cgo)
                
                # RCGOéœ€è¦é€šè¿‡å›å½’è·å¾—æ®‹å·®ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                # è¿™é‡Œç®€åŒ–ï¼šä½¿ç”¨CGOå‡å»å¸‚åœºå‡å€¼
                rcgo = cgo  # å®é™…åº”è¯¥å›å½’å»ç›¸å…³
                rcgo_values.append(rcgo)
            
            stock_data['CGO'] = cgo_values
            stock_data['RCGO'] = rcgo_values
            
            cgo_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'CGO']])
            rcgo_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'RCGO']])
        
        cgo_df = pd.concat(cgo_list, ignore_index=True)
        cgo_wide = self.pivot_to_wide_format(cgo_df, 'CGO')
        
        rcgo_df = pd.concat(rcgo_list, ignore_index=True)
        rcgo_wide = self.pivot_to_wide_format(rcgo_df, 'RCGO')
        
        print(f"âœ… CGO & RCGOå› å­è®¡ç®—å®Œæˆ")
        return cgo_wide, rcgo_wide
    
    # ==================== Factor 15: SUE ====================
    def calculate_SUE(self):
        """
        Factor 15: Standardized Unexpected Earnings (SUE)
        æ ‡å‡†åŒ–æ„å¤–æ”¶ç›Šï¼Œéœ€è¦è´¢åŠ¡æ•°æ®ï¼ˆEPSï¼‰
        è¿™é‡Œæä¾›æ¡†æ¶ï¼Œå®é™…éœ€è¦EPSæ•°æ®
        """
        print("è®¡ç®—å› å­15: SUE...")
        print("âš ï¸  SUEå› å­éœ€è¦EPSè´¢åŠ¡æ•°æ®ï¼Œå½“å‰æ•°æ®é›†ä¸­ä¸åŒ…å«ï¼Œè¿”å›ç©ºDataFrame")
        
        # åˆ›å»ºç©ºçš„DataFrameç»“æ„
        dates = self.price_data['TRADE_DT'].unique()
        stocks = self.price_data['S_INFO_WINDCODE'].unique()
        sue_wide = pd.DataFrame(index=stocks, columns=dates)
        sue_wide[:] = np.nan
        
        print("âœ… SUEå› å­æ¡†æ¶å·²åˆ›å»ºï¼ˆéœ€è¦EPSæ•°æ®å¡«å……ï¼‰")
        return sue_wide
    
    # ==================== Factor 16-17: Candle Shadow Factors ====================
    def calculate_CandleShadowFactors(self, window=20, norm_window=5):
        """
        Factor 16-17: CandleAbove & CandleBelow shadow factors
        Kçº¿å›¾ä¸Šå½±çº¿å’Œä¸‹å½±çº¿å› å­
        """
        print("è®¡ç®—å› å­16-17: CandleShadowFactors...")
        
        above_mean_list, above_std_list = [], []
        below_mean_list, below_std_list = [], []
        
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
            
            # è®¡ç®—ä¸Šå½±çº¿é•¿åº¦ = max(å¼€ç›˜ä»·, æ”¶ç›˜ä»·) - æœ€é«˜ä»·çš„ç»å¯¹å€¼
            stock_data['UPPER_SHADOW'] = np.abs(stock_data[['OPEN_PRICE', 'CLOSE_PRICE']].max(axis=1) - stock_data['HIGH_PRICE'])
            
            # è®¡ç®—ä¸‹å½±çº¿é•¿åº¦ = æœ€ä½ä»· - min(å¼€ç›˜ä»·, æ”¶ç›˜ä»·)
            stock_data['LOWER_SHADOW'] = stock_data['LOW_PRICE'] - stock_data[['OPEN_PRICE', 'CLOSE_PRICE']].min(axis=1)
            
            # 5æ—¥å‡å€¼æ ‡å‡†åŒ–
            stock_data['UPPER_SHADOW_NORM'] = stock_data['UPPER_SHADOW'] / (stock_data['UPPER_SHADOW'].rolling(window=norm_window).mean() + 1e-8)
            stock_data['LOWER_SHADOW_NORM'] = stock_data['LOWER_SHADOW'] / (stock_data['LOWER_SHADOW'].rolling(window=norm_window).mean() + 1e-8)
            
            # 20æ—¥å‡å€¼å’Œæ ‡å‡†å·®
            stock_data['CANDLE_ABOVE_MEAN'] = stock_data['UPPER_SHADOW_NORM'].rolling(window=window).mean()
            stock_data['CANDLE_ABOVE_STD'] = stock_data['UPPER_SHADOW_NORM'].rolling(window=window).std()
            stock_data['CANDLE_BELOW_MEAN'] = stock_data['LOWER_SHADOW_NORM'].rolling(window=window).mean()
            stock_data['CANDLE_BELOW_STD'] = stock_data['LOWER_SHADOW_NORM'].rolling(window=window).std()
            
            above_mean_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'CANDLE_ABOVE_MEAN']])
            above_std_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'CANDLE_ABOVE_STD']])
            below_mean_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'CANDLE_BELOW_MEAN']])
            below_std_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'CANDLE_BELOW_STD']])
        
        factors = {}
        for name, data_list in [
            ('CANDLE_ABOVE_MEAN', above_mean_list),
            ('CANDLE_ABOVE_STD', above_std_list),
            ('CANDLE_BELOW_MEAN', below_mean_list),
            ('CANDLE_BELOW_STD', below_std_list)
        ]:
            factor_df = pd.concat(data_list, ignore_index=True)
            factors[name] = self.pivot_to_wide_format(factor_df, name)
        
        print(f"âœ… CandleShadowFactorså› å­è®¡ç®—å®Œæˆ")
        return factors
    
    # ==================== Factor 18-19: Williams Shadow Factors ====================
    def calculate_WilliamsShadowFactors(self, window=20, norm_window=5):
        """
        Factor 18-19: WilliamsAbove & WilliamsBelow shadow factors
        åŸºäºæ”¶ç›˜ä»·çš„Williamsä¸Šå½±çº¿å’Œä¸‹å½±çº¿å› å­
        """
        print("è®¡ç®—å› å­18-19: WilliamsShadowFactors...")
        
        williams_above_mean_list, williams_above_std_list = [], []
        williams_below_mean_list, williams_below_std_list = [], []
        
        for stock in self.price_data['S_INFO_WINDCODE'].unique():
            stock_data = self.price_data[self.price_data['S_INFO_WINDCODE'] == stock].sort_values('TRADE_DT').copy()
            
            # åŸºäºæ”¶ç›˜ä»·é‡æ–°å®šä¹‰ä¸Šå½±çº¿å’Œä¸‹å½±çº¿
            stock_data['WILLIAMS_UPPER_SHADOW'] = np.abs(stock_data['CLOSE_PRICE'] - stock_data['HIGH_PRICE'])
            stock_data['WILLIAMS_LOWER_SHADOW'] = stock_data['CLOSE_PRICE'] - stock_data['LOW_PRICE']
            
            # 5æ—¥å‡å€¼æ ‡å‡†åŒ–
            stock_data['WILLIAMS_UPPER_SHADOW_NORM'] = stock_data['WILLIAMS_UPPER_SHADOW'] / (stock_data['WILLIAMS_UPPER_SHADOW'].rolling(window=norm_window).mean() + 1e-8)
            stock_data['WILLIAMS_LOWER_SHADOW_NORM'] = stock_data['WILLIAMS_LOWER_SHADOW'] / (stock_data['WILLIAMS_LOWER_SHADOW'].rolling(window=norm_window).mean() + 1e-8)
            
            # 20æ—¥å‡å€¼å’Œæ ‡å‡†å·®
            stock_data['WILLIAMS_ABOVE_MEAN'] = stock_data['WILLIAMS_UPPER_SHADOW_NORM'].rolling(window=window).mean()
            stock_data['WILLIAMS_ABOVE_STD'] = stock_data['WILLIAMS_UPPER_SHADOW_NORM'].rolling(window=window).std()
            stock_data['WILLIAMS_BELOW_MEAN'] = stock_data['WILLIAMS_LOWER_SHADOW_NORM'].rolling(window=window).mean()
            stock_data['WILLIAMS_BELOW_STD'] = stock_data['WILLIAMS_LOWER_SHADOW_NORM'].rolling(window=window).std()
            
            williams_above_mean_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'WILLIAMS_ABOVE_MEAN']])
            williams_above_std_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'WILLIAMS_ABOVE_STD']])
            williams_below_mean_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'WILLIAMS_BELOW_MEAN']])
            williams_below_std_list.append(stock_data[['S_INFO_WINDCODE', 'TRADE_DT', 'WILLIAMS_BELOW_STD']])
        
        factors = {}
        for name, data_list in [
            ('WILLIAMS_ABOVE_MEAN', williams_above_mean_list),
            ('WILLIAMS_ABOVE_STD', williams_above_std_list),
            ('WILLIAMS_BELOW_MEAN', williams_below_mean_list),
            ('WILLIAMS_BELOW_STD', williams_below_std_list)
        ]:
            factor_df = pd.concat(data_list, ignore_index=True)
            factors[name] = self.pivot_to_wide_format(factor_df, name)
        
        print(f"âœ… WilliamsShadowFactorså› å­è®¡ç®—å®Œæˆ")
        return factors
    
    # ==================== Factor 20: UBL ====================
    def calculate_UBL(self, candle_above_std, williams_below_mean):
        """
        Factor 20: UBL (Up & Bottom Line) factor
        ç»¼åˆä¸Šå½±çº¿å’Œä¸‹å½±çº¿å› å­
        """
        print("è®¡ç®—å› å­20: UBL...")
        
        # å¯¹é½æ—¥æœŸå’Œè‚¡ç¥¨
        common_dates = set(candle_above_std.columns) & set(williams_below_mean.columns)
        common_stocks = set(candle_above_std.index) & set(williams_below_mean.index)
        
        candle_above_std_aligned = candle_above_std.loc[list(common_stocks), list(common_dates)]
        williams_below_mean_aligned = williams_below_mean.loc[list(common_stocks), list(common_dates)]
        
        # å¸‚å€¼ä¸­æ€§åŒ–ï¼ˆç®€åŒ–å¤„ç†ï¼šæˆªé¢æ ‡å‡†åŒ–ï¼‰
        # å®é™…åº”è¯¥æŒ‰å¸‚å€¼åˆ†ç»„è¿›è¡Œä¸­æ€§åŒ–
        candle_above_std_neutral = candle_above_std_aligned.sub(candle_above_std_aligned.mean(axis=0), axis=1)
        williams_below_mean_neutral = williams_below_mean_aligned.sub(williams_below_mean_aligned.mean(axis=0), axis=1)
        
        # æˆªé¢æ ‡å‡†åŒ–
        candle_above_std_std = candle_above_std_neutral.div(candle_above_std_neutral.std(axis=0) + 1e-8, axis=1)
        williams_below_mean_std = williams_below_mean_neutral.div(williams_below_mean_neutral.std(axis=0) + 1e-8, axis=1)
        
        # ç­‰æƒçº¿æ€§ç»„åˆ
        ubl = (candle_above_std_std + williams_below_mean_std) / 2
        
        print(f"âœ… UBLå› å­è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {ubl.shape}")
        return ubl
    
    # ==================== è®¡ç®—æ‰€æœ‰å› å­ ====================
    def calculate_all_factors(self, filter_by_constituents=False):
        """
        è®¡ç®—æ‰€æœ‰20ä¸ªå› å­
        
        Parameters:
        -----------
        filter_by_constituents : bool
            æ˜¯å¦åœ¨è®¡ç®—å®Œæˆåè¿‡æ»¤éæˆåˆ†è‚¡çš„å› å­å€¼ã€‚
            Falseï¼ˆé»˜è®¤ï¼‰ï¼šä¿ç•™æ‰€æœ‰è‚¡ç¥¨çš„å› å­å€¼ï¼ˆæ¨èï¼Œå› ä¸ºå›æµ‹é˜¶æ®µä¼šè¿‡æ»¤ï¼‰
            Trueï¼šåªä¿ç•™æˆåˆ†è‚¡çš„å› å­å€¼ï¼ˆé€‚ç”¨äºæŸäº›éœ€è¦æˆªé¢æ•°æ®çš„å› å­ï¼‰
        
        Returns:
        --------
        dict : æ‰€æœ‰å› å­æ•°æ®
        """
        print("\n" + "="*60)
        print("å¼€å§‹è®¡ç®—æ‰€æœ‰å› å­...")
        print("="*60 + "\n")
        
        all_factors = {}
        
        # Factor 1-2
        all_factors['SCC'] = self.calculate_SCC()
        all_factors['TCC'] = self.calculate_TCC()
        
        # Factor 3
        all_factors['APB'] = self.calculate_APB()
        
        # Factor 4-7
        relative_cost_factors = self.calculate_relative_cost_moments()
        all_factors.update(relative_cost_factors)
        
        # Factor 8-10
        all_factors['BIAS'] = self.calculate_BIAS()
        all_factors['TURNOVER_BIAS'] = self.calculate_TurnoverBias()
        all_factors['NEW_HIGH_RATIO'] = self.calculate_NewHighRatio()
        
        # Factor 11
        vol_factor, vol_decorr = self.calculate_VolatilityFactor()
        all_factors['ID_VOL'] = vol_factor
        all_factors['ID_VOL_DECORR'] = vol_decorr
        
        # Factor 12
        all_factors['TURN20'] = self.calculate_TurnoverFactor()
        
        # Factor 13-14
        cgo, rcgo = self.calculate_CGO_RCGO()
        all_factors['CGO'] = cgo
        all_factors['RCGO'] = rcgo
        
        # Factor 15
        all_factors['SUE'] = self.calculate_SUE()
        
        # Factor 16-17
        candle_factors = self.calculate_CandleShadowFactors()
        all_factors.update(candle_factors)
        
        # Factor 18-19
        williams_factors = self.calculate_WilliamsShadowFactors()
        all_factors.update(williams_factors)
        
        # Factor 20
        all_factors['UBL'] = self.calculate_UBL(
            all_factors['CANDLE_ABOVE_STD'],
            all_factors['WILLIAMS_BELOW_MEAN']
        )
        
        # å¯é€‰ï¼šæ ¹æ®æˆåˆ†è‚¡è¿‡æ»¤å› å­å€¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # æ³¨æ„ï¼šé»˜è®¤ä¸è¿‡æ»¤ï¼Œå› ä¸ºå›æµ‹é˜¶æ®µä¼šæ­£ç¡®è¿‡æ»¤ã€‚ä½†å¦‚æœéœ€è¦åªä¿ç•™æˆåˆ†è‚¡çš„å› å­å€¼ï¼Œå¯ä»¥å¯ç”¨
        if filter_by_constituents and self.constituent_manager is not None:
            print("\næ ¹æ®æˆåˆ†è‚¡è¿‡æ»¤å› å­å€¼...")
            for factor_name, factor_df in all_factors.items():
                if factor_df is None or factor_df.empty:
                    continue
                # å¯¹æ¯ä¸ªæ—¥æœŸï¼Œåªä¿ç•™è¯¥æ—¥æœŸçš„æˆåˆ†è‚¡
                filtered_factor = factor_df.copy()
                for date in factor_df.columns:
                    constituents = self.constituent_manager.get_constituents_by_date(date)
                    constituents_set = set(constituents)
                    # å°†éæˆåˆ†è‚¡çš„å› å­å€¼è®¾ä¸ºNaN
                    mask = ~factor_df.index.isin(constituents_set)
                    filtered_factor.loc[mask, date] = np.nan
                all_factors[factor_name] = filtered_factor
            print("âœ… å› å­å€¼å·²æ ¹æ®æˆåˆ†è‚¡è¿‡æ»¤")
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰å› å­è®¡ç®—å®Œæˆï¼")
        print("="*60 + "\n")
        
        return all_factors


# ==================== å¹¶è¡Œè®¡ç®—è¾…åŠ©å‡½æ•° ====================

# ==================== NumbaåŠ é€Ÿå‡½æ•° ====================

if NUMBA_AVAILABLE:
    @jit(nopython=True)
    def _calculate_scc_optimized(returns_window):
        """
        ä½¿ç”¨numbaåŠ é€Ÿçš„SCCè®¡ç®—
        returns_window: numpyæ•°ç»„ (n_stocks, n_dates)
        """
        n_stocks, n_dates = returns_window.shape
        avg_corr = np.full(n_stocks, np.nan, dtype=np.float64)
        
        # è®¡ç®—æ¯åªè‚¡ç¥¨çš„å¹³å‡ç›¸å…³ç³»æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…ä½¿ç”¨åˆ—è¡¨ï¼‰
        for i in range(n_stocks):
            stock_i = returns_window[i, :]
            if np.isnan(stock_i).all():
                continue
            
            # è®¡ç®—ä¸æ‰€æœ‰å…¶ä»–è‚¡ç¥¨çš„ç›¸å…³æ€§æ€»å’Œå’Œè®¡æ•°
            corr_sum = 0.0
            corr_count = 0
            
            for j in range(n_stocks):
                if i == j:
                    continue
                stock_j = returns_window[j, :]
                
                # æ‰¾åˆ°åŒæ—¶æœ‰æ•ˆçš„æ—¥æœŸ
                valid_count = 0
                sum_i = 0.0
                sum_j = 0.0
                sum_ij = 0.0
                sum_i2 = 0.0
                sum_j2 = 0.0
                
                for k in range(n_dates):
                    if not (np.isnan(stock_i[k]) or np.isnan(stock_j[k])):
                        valid_count += 1
                        sum_i += stock_i[k]
                        sum_j += stock_j[k]
                        sum_ij += stock_i[k] * stock_j[k]
                        sum_i2 += stock_i[k] * stock_i[k]
                        sum_j2 += stock_j[k] * stock_j[k]
                
                if valid_count < n_dates // 2:  # è‡³å°‘éœ€è¦ä¸€åŠçš„æœ‰æ•ˆæ•°æ®
                    continue
                
                # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
                mean_i = sum_i / valid_count
                mean_j = sum_j / valid_count
                
                # è®¡ç®—æ–¹å·®
                var_i = (sum_i2 / valid_count) - (mean_i * mean_i)
                var_j = (sum_j2 / valid_count) - (mean_j * mean_j)
                
                if var_i > 1e-8 and var_j > 1e-8:
                    # è®¡ç®—åæ–¹å·®
                    cov_ij = (sum_ij / valid_count) - (mean_i * mean_j)
                    # è®¡ç®—ç›¸å…³ç³»æ•°
                    corr = cov_ij / (np.sqrt(var_i) * np.sqrt(var_j))
                    if not np.isnan(corr) and not np.isinf(corr):
                        corr_sum += corr
                        corr_count += 1
            
            if corr_count > 0:
                avg_corr[i] = corr_sum / corr_count
        
        return avg_corr

    @jit(nopython=True)
    def _calculate_weighted_moments_numba(values, weights):
        """ä½¿ç”¨numbaåŠ é€Ÿçš„åŠ æƒçŸ©è®¡ç®—"""
        n = len(values)
        if n == 0:
            return np.nan, np.nan, np.nan, np.nan
        
        # å»é™¤NaN
        valid_values = np.empty(n, dtype=np.float64)
        valid_weights = np.empty(n, dtype=np.float64)
        valid_count = 0
        
        weight_sum = 0.0
        for i in range(n):
            if not np.isnan(values[i]) and not np.isnan(weights[i]) and weights[i] > 0:
                valid_values[valid_count] = values[i]
                valid_weights[valid_count] = weights[i]
                weight_sum += weights[i]
                valid_count += 1
        
        if valid_count == 0:
            return np.nan, np.nan, np.nan, np.nan
        
        # å½’ä¸€åŒ–æƒé‡
        for i in range(valid_count):
            valid_weights[i] = valid_weights[i] / weight_sum
        
        # ä¸€é˜¶çŸ©ï¼ˆå‡å€¼ï¼‰
        mean_val = 0.0
        for i in range(valid_count):
            mean_val += valid_values[i] * valid_weights[i]
        
        # äºŒé˜¶çŸ©ï¼ˆæ–¹å·®ï¼‰
        variance = 0.0
        for i in range(valid_count):
            variance += ((valid_values[i] - mean_val) ** 2) * valid_weights[i]
        
        # ä¸‰é˜¶æ ‡å‡†åŒ–çŸ©ï¼ˆååº¦ï¼‰
        if variance > 1e-8:
            skewness = 0.0
            for i in range(valid_count):
                skewness += ((valid_values[i] - mean_val) ** 3) * valid_weights[i]
            skewness = skewness / (variance ** 1.5)
        else:
            skewness = 0.0
        
        # å››é˜¶æ ‡å‡†åŒ–çŸ©ï¼ˆå³°åº¦ï¼‰
        if variance > 1e-8:
            kurt = 0.0
            for i in range(valid_count):
                kurt += ((valid_values[i] - mean_val) ** 4) * valid_weights[i]
            kurt = kurt / (variance ** 2) - 3.0
        else:
            kurt = 0.0
        
        return mean_val, variance, skewness, kurt
    
    @jit(nopython=True)
    def _rolling_mean_std_numba(values, window):
        """ä½¿ç”¨numbaåŠ é€Ÿçš„æ»šåŠ¨å‡å€¼å’Œæ ‡å‡†å·®è®¡ç®—"""
        n = len(values)
        means = np.full(n, np.nan, dtype=np.float64)
        stds = np.full(n, np.nan, dtype=np.float64)
        
        for i in range(window - 1, n):
            window_data = values[i - window + 1:i + 1]
            valid_mask = ~np.isnan(window_data)
            
            if valid_mask.sum() >= window // 2:  # è‡³å°‘éœ€è¦ä¸€åŠçš„æœ‰æ•ˆæ•°æ®
                valid_data = window_data[valid_mask]
                means[i] = np.mean(valid_data)
                stds[i] = np.std(valid_data)
        
        return means, stds
else:
    # å¦‚æœnumbaä¸å¯ç”¨ï¼Œæä¾›å›é€€å®ç°
    def _calculate_scc_optimized(returns_window):
        """å›é€€åˆ°numpyå®ç°"""
        return np.full(returns_window.shape[0], np.nan)
    
    def _calculate_weighted_moments_numba(values, weights):
        """å›é€€åˆ°numpyå®ç°"""
        valid_mask = ~(np.isnan(values) | np.isnan(weights))
        if valid_mask.sum() == 0:
            return np.nan, np.nan, np.nan, np.nan
        
        valid_values = values[valid_mask]
        valid_weights = weights[valid_mask]
        valid_weights = valid_weights / np.sum(valid_weights)
        
        mean_val = np.sum(valid_values * valid_weights)
        variance = np.sum(((valid_values - mean_val) ** 2) * valid_weights)
        
        if variance > 1e-8:
            skewness = np.sum(((valid_values - mean_val) ** 3) * valid_weights) / (variance ** 1.5)
            kurt = np.sum(((valid_values - mean_val) ** 4) * valid_weights) / (variance ** 2) - 3.0
        else:
            skewness = 0.0
            kurt = 0.0
        
        return mean_val, variance, skewness, kurt
    
    def _rolling_mean_std_numba(values, window):
        """å›é€€åˆ°numpyå®ç°"""
        means = pd.Series(values).rolling(window=window).mean().values
        stds = pd.Series(values).rolling(window=window).std().values
        return means, stds


# ==================== ä¸»å‡½æ•° ====================

def load_data_from_local(data_path='./data/'):
    """
    ä»æœ¬åœ°CSVæ–‡ä»¶åŠ è½½æ•°æ®
    
    Parameters:
    -----------
    data_path : str, æ•°æ®æ–‡ä»¶è·¯å¾„
    
    Returns:
    --------
    dict : åŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸
    """
    data = {}
    data_path = Path(data_path)
    
    try:
        # åŠ è½½ä»·æ ¼æ•°æ®
        price_file = data_path / 'stock_price_data.csv'
        if price_file.exists():
            print(f"ğŸ“‚ åŠ è½½ä»·æ ¼æ•°æ®: {price_file}")
            data['price_data'] = pd.read_csv(price_file, encoding='utf-8-sig')
            data['price_data']['TRADE_DT'] = pd.to_datetime(data['price_data']['TRADE_DT'])
            print(f"   âœ… {len(data['price_data'])} æ¡è®°å½•")
        else:
            print(f"   âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {price_file}")
        
        # åŠ è½½å¸‚å€¼æ•°æ®
        mv_file = data_path / 'market_value_data.csv'
        if mv_file.exists():
            print(f"ğŸ“‚ åŠ è½½å¸‚å€¼æ•°æ®: {mv_file}")
            data['mv_data'] = pd.read_csv(mv_file, encoding='utf-8-sig')
            data['mv_data']['TRADE_DT'] = pd.to_datetime(data['mv_data']['TRADE_DT'])
            print(f"   âœ… {len(data['mv_data'])} æ¡è®°å½•")
        else:
            print(f"   âš ï¸  æœªæ‰¾åˆ°æ–‡ä»¶: {mv_file}")
        
        # åŠ è½½æ¢æ‰‹ç‡æ•°æ®
        turnover_file = data_path / 'turnover_rate_data.csv'
        if turnover_file.exists():
            print(f"ğŸ“‚ åŠ è½½æ¢æ‰‹ç‡æ•°æ®: {turnover_file}")
            data['turnover_data'] = pd.read_csv(turnover_file, encoding='utf-8-sig')
            data['turnover_data']['TRADE_DT'] = pd.to_datetime(data['turnover_data']['TRADE_DT'])
            print(f"   âœ… {len(data['turnover_data'])} æ¡è®°å½•")
        else:
            print(f"   âš ï¸  æœªæ‰¾åˆ°æ–‡ä»¶: {turnover_file}")
        
        # åŠ è½½å¸‚åœºæ•°æ®
        market_file = data_path / 'market_index_data.csv'
        if market_file.exists():
            print(f"ğŸ“‚ åŠ è½½å¸‚åœºæ•°æ®: {market_file}")
            data['market_data'] = pd.read_csv(market_file, encoding='utf-8-sig')
            data['market_data']['TRADE_DT'] = pd.to_datetime(data['market_data']['TRADE_DT'])
            print(f"   âœ… {len(data['market_data'])} æ¡è®°å½•")
        else:
            print(f"   âš ï¸  æœªæ‰¾åˆ°æ–‡ä»¶: {market_file}")
        
        # åŠ è½½æˆåˆ†è‚¡å†å²æ•°æ®ï¼ˆå¯é€‰ï¼‰
        constituents_file = data_path / 'csi1000_constituents_history.csv'
        if constituents_file.exists():
            print(f"ğŸ“‚ åŠ è½½æˆåˆ†è‚¡å†å²æ•°æ®: {constituents_file}")
            data['constituents_history'] = pd.read_csv(constituents_file, encoding='utf-8-sig')
            data['constituents_history']['S_CON_INDATE'] = pd.to_datetime(
                data['constituents_history']['S_CON_INDATE'], errors='coerce'
            )
            data['constituents_history']['S_CON_OUTDATE'] = pd.to_datetime(
                data['constituents_history']['S_CON_OUTDATE'], errors='coerce'
            )
            print(f"   âœ… {len(data['constituents_history'])} æ¡è®°å½•")
        else:
            print(f"   âš ï¸  æœªæ‰¾åˆ°æ–‡ä»¶: {constituents_file}ï¼ˆæˆåˆ†è‚¡è¿‡æ»¤å°†ä¸å¯ç”¨ï¼‰")
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    return data


def save_factors_to_local(all_factors, factors_path='./factors/'):
    """
    ä¿å­˜å› å­æ•°æ®åˆ°æœ¬åœ°CSVæ–‡ä»¶
    
    Parameters:
    -----------
    all_factors : dict, å› å­æ•°æ®å­—å…¸
    factors_path : str, å› å­ä¿å­˜è·¯å¾„
    """
    factors_path = Path(factors_path)
    factors_path.mkdir(parents=True, exist_ok=True)
    
    saved_count = 0
    failed_count = 0
    
    print(f"\nğŸ’¾ ä¿å­˜å› å­æ•°æ®åˆ°: {factors_path.absolute()}")
    
    for factor_name, factor_df in all_factors.items():
        if factor_df is None or factor_df.empty:
            print(f"   âš ï¸  {factor_name}: æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
            failed_count += 1
            continue
        
        try:
            factor_file = factors_path / f'{factor_name}.csv'
            factor_df.to_csv(factor_file, encoding='utf-8-sig')
            print(f"   âœ… {factor_name}: {factor_df.shape} -> {factor_file.name}")
            saved_count += 1
        except Exception as e:
            print(f"   âŒ {factor_name}: ä¿å­˜å¤±è´¥ - {e}")
            failed_count += 1
    
    print(f"\nâœ… ä¿å­˜å®Œæˆ: {saved_count} ä¸ªå› å­æˆåŠŸï¼Œ{failed_count} ä¸ªå¤±è´¥")


def main(data_path='./data/', factors_path='./factors/', use_parallel=True, n_jobs=-1):
    """
    ä¸»å‡½æ•°ï¼šä»æœ¬åœ°æ•°æ®è®¡ç®—å› å­å¹¶ä¿å­˜
    
    Parameters:
    -----------
    data_path : str, æ•°æ®æ–‡ä»¶è·¯å¾„
    factors_path : str, å› å­ä¿å­˜è·¯å¾„
    use_parallel : bool, æ˜¯å¦ä½¿ç”¨å¹¶è¡Œè®¡ç®—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    n_jobs : int, å¹¶è¡Œä»»åŠ¡æ•°ï¼Œ-1è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
    """
    print("="*80)
    print("ä¸­è¯1000å¤šå› å­è®¡ç®— - æœ¬åœ°æ•°æ®ç‰ˆæœ¬")
    print("="*80 + "\n")
    
    # 1. åŠ è½½æ•°æ®
    print("ã€æ­¥éª¤1ã€‘åŠ è½½æœ¬åœ°æ•°æ®")
    print("-"*80)
    data = load_data_from_local(data_path)
    
    if 'price_data' not in data or data['price_data'].empty:
        print("âŒ ä»·æ ¼æ•°æ®ç¼ºå¤±ï¼Œç¨‹åºç»ˆæ­¢")
        return None
    
    # 2. åˆå§‹åŒ–æˆåˆ†è‚¡ç®¡ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    constituent_manager = None
    if 'constituents_history' in data and not data['constituents_history'].empty:
        try:
            from constituent_manager import ConstituentManager
            constituent_manager = ConstituentManager(data['constituents_history'])
            print(f"\nâœ… æˆåˆ†è‚¡ç®¡ç†å™¨å·²åˆå§‹åŒ–")
        except ImportError:
            print(f"\nâš ï¸  æ— æ³•å¯¼å…¥ConstituentManagerï¼Œè·³è¿‡æˆåˆ†è‚¡ç®¡ç†")
    
    # 3. åˆå§‹åŒ–å› å­è®¡ç®—å™¨
    print("\nã€æ­¥éª¤2ã€‘åˆå§‹åŒ–å› å­è®¡ç®—å™¨")
    print("-"*80)
    calculator = FactorCalculator(
        price_data=data['price_data'],
        mv_data=data.get('mv_data'),
        turnover_data=data.get('turnover_data'),
        market_data=data.get('market_data'),
        constituent_manager=constituent_manager
    )
    print(f"âœ… ä»·æ ¼æ•°æ®é¢„å¤„ç†å®Œæˆ: {len(calculator.price_data)} æ¡è®°å½•")
    print(f"   è‚¡ç¥¨æ•°é‡: {calculator.price_data['S_INFO_WINDCODE'].nunique()}")
    print(f"   æ—¥æœŸèŒƒå›´: {calculator.price_data['TRADE_DT'].min()} è‡³ {calculator.price_data['TRADE_DT'].max()}")
    
    # 4. è®¡ç®—æ‰€æœ‰å› å­
    print("\nã€æ­¥éª¤3ã€‘è®¡ç®—æ‰€æœ‰å› å­")
    print("-"*80)
    if NUMBA_AVAILABLE:
        print(f"âœ… ä½¿ç”¨numba JITåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰")
    else:
        print(f"âš ï¸  numbaä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†numpyè®¡ç®—")
    
    start_time = time.time()
    
    all_factors = calculator.calculate_all_factors(filter_by_constituents=False)
    
    elapsed_time = time.time() - start_time
    print(f"\nâ±ï¸  å› å­è®¡ç®—è€—æ—¶: {elapsed_time:.2f} ç§’ ({elapsed_time/60:.2f} åˆ†é’Ÿ)")
    
    # 5. ä¿å­˜å› å­æ•°æ®
    print("\nã€æ­¥éª¤4ã€‘ä¿å­˜å› å­æ•°æ®")
    print("-"*80)
    save_factors_to_local(all_factors, factors_path)
    
    # 6. ç”Ÿæˆå› å­æ±‡æ€»ä¿¡æ¯
    print("\nã€æ­¥éª¤5ã€‘å› å­æ±‡æ€»ä¿¡æ¯")
    print("-"*80)
    factor_summary = []
    for factor_name, factor_df in all_factors.items():
        if factor_df is not None and not factor_df.empty:
            factor_summary.append({
                'å› å­åç§°': factor_name,
                'è‚¡ç¥¨æ•°': factor_df.shape[0],
                'æ—¥æœŸæ•°': factor_df.shape[1],
                'ç¼ºå¤±ç‡': (factor_df.isna().sum().sum() / (factor_df.shape[0] * factor_df.shape[1]) * 100)
            })
    
    summary_df = pd.DataFrame(factor_summary)
    summary_file = Path(factors_path) / 'factor_summary.csv'
    summary_df.to_csv(summary_file, index=False, encoding='utf-8-sig')
    print(f"âœ… å› å­æ±‡æ€»å·²ä¿å­˜: {summary_file}")
    print(f"\nå› å­ç»Ÿè®¡:")
    print(summary_df.to_string(index=False))
    
    print("\n" + "="*80)
    print("âœ… å› å­è®¡ç®—å®Œæˆï¼")
    print("="*80)
    
    return all_factors


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸­è¯1000å¤šå› å­è®¡ç®—')
    parser.add_argument('--data_path', type=str, default='d:/programme/vscode_c/courses/Software Enginerring/data/',
                        help='æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: ./data/ï¼‰')
    parser.add_argument('--factors_path', type=str, default='d:/programme/vscode_c/courses/Software Enginerring/factors/',
                        help='å› å­ä¿å­˜è·¯å¾„ï¼ˆé»˜è®¤: ./factors/ï¼‰')
    parser.add_argument('--no_parallel', action='store_true',
                        help='ç¦ç”¨å¹¶è¡Œè®¡ç®—')
    parser.add_argument('--n_jobs', type=int, default=-1,
                        help='å¹¶è¡Œä»»åŠ¡æ•°ï¼ˆ-1è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒï¼‰')
    
    args = parser.parse_args()
    
    try:
        all_factors = main(
            data_path=args.data_path,
            factors_path=args.factors_path,
            use_parallel=not args.no_parallel,
            n_jobs=args.n_jobs
        )
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
